{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Neural Networks Foundation — From Theory to Practice\n",
        "jupyter: python3\n",
        "execute:\n",
        "  freeze: true\n",
        "  echo: true\n",
        "toc: true\n",
        "toc-depth: 4\n",
        "number-sections: true\n",
        "format:\n",
        "  html:\n",
        "    toc-expand: false\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0meHXxPBcIax"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "For any machine learning or deep learning model to improve, it must learn from its own performance—specifically, by iteratively adjusting its parameters (weights) until predictions align with reality.\n",
        "\n",
        "Stochastic Gradient Descent (SGD) is the cornerstone of this optimization process and remains the  widely used optimization algorithm in modern AI.\n",
        "\n",
        "In this article, I'll:\n",
        "* Build an intuitive understanding of SGD.\n",
        "* Walk through a simple example of gradient descent.\n",
        "* Apply these concepts by creating a learner from scratch and training it on the MNIST dataset.\n",
        "\n",
        "# The Intuition Behind Gradient Descent\n",
        "\n",
        "Consider the case where we have a set of 2-D points $p(x, y)$ emulating a natural phenomenon, and we want to model their behavior using a quadratic equation:\n",
        "\n",
        "$y = a.x^2 + b.x + c$\n",
        "\n",
        "To find the best values for $a$, $b$, and $c$, we usually would:\n",
        "\n",
        "* Choose initial (random) values for $a$, $b$, and $c$.\n",
        "\n",
        "* Make predictions $\\hat{y}$ for all $x$ using these weights.\n",
        "\n",
        "* Compare predictions to the true $y$ values and compute the error.\n",
        "\n",
        "* Figure out how to adjust $a$, $b$, and $c$ to reduce the error (increase or decrease).\n",
        "\n",
        "* Repeat this process until the error is as small as possible.\n",
        "\n",
        "However, how would we instill this intuition on how to correctly adjust the weights to our model?\n",
        "\n",
        "The answer lies in gradient descent.\n",
        "\n",
        "The idea behind gradient descent is to compute the derivative of a function ( in our case, the error function) at some point (the point being the weights chosen). This will tell us how steeply the error changes with respect to each parameter.\n",
        "\n",
        "And since we are trying to minimize this error, take iterative steps in the opposite direction of the gradient because that's where the steepest descent is.\n",
        "\n",
        "$ w=w - η⋅∇L $\n",
        "\n",
        "Where:\n",
        "\n",
        "  $\\eta$ is the learning rate\n",
        "\n",
        "  $\\nabla{L}$ is the gradient of the loss function\n",
        "\n",
        "## Example\n",
        "\n",
        "Let's say our loss function is as follow:\n",
        "\n",
        " $f(w) = (w -5)^2 $\n",
        "\n",
        " At first glance, it is obvious that the value of $w$ that would minimize $f(w)$ is 5.\n",
        "\n",
        " But let's do that with SGD.\n",
        " * Start with $w_0 = 0$, and a learning rate $\\eta = 0.1$.\n",
        " * Compute gradient $\\nabla{f(w)} = 2 * (w -5)$\n",
        " * Iteration 1:\n",
        " $w_1 = w_0 - \\eta⋅\\nabla{f(w_0)} = 0 - 0.1 * 2(0 - 5) = 1  $\n",
        "\n",
        "  * Iteration 2:\n",
        " $w_2 = w_1 - \\eta⋅\\nabla{f(w_1)} = 1 - 0.1 * 2(1 - 5) = 1.4  $\n",
        "\n",
        "As we can see each step is moving us closer to the solution $w = 5$.\n",
        "## Why \"Stochastic\"?\n",
        "\n",
        "In Stochastic Gradient Descent (SGD), instead of computing the gradient using the entire dataset at once—which would be computationally heavy, we use just one data point or a small random batch.\n",
        "This makes updates faster and helps the model escape local minima, as it adds a bit of randomness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "ZSBVSoWidk_d",
        "outputId": "4f327f94-365a-482f-c953-9204f095c4df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n"
          ]
        },
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 2.43.0 (0)\n",
              " -->\n",
              "<!-- Title: %3 Pages: 1 -->\n",
              "<svg width=\"135pt\" height=\"423pt\"\n",
              " viewBox=\"0.00 0.00 134.65 423.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 419)\">\n",
              "<title>%3</title>\n",
              "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-419 130.65,-419 130.65,4 -4,4\"/>\n",
              "<!-- init -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>init</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.65\" cy=\"-397\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"79.65\" y=\"-393.3\" font-family=\"Times,serif\" font-size=\"14.00\">init</text>\n",
              "</g>\n",
              "<!-- predict -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>predict</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.65\" cy=\"-324\" rx=\"35.19\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"79.65\" y=\"-320.3\" font-family=\"Times,serif\" font-size=\"14.00\">predict</text>\n",
              "</g>\n",
              "<!-- init&#45;&gt;predict -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>init&#45;&gt;predict</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M79.65,-378.81C79.65,-370.79 79.65,-361.05 79.65,-352.07\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"83.15,-352.03 79.65,-342.03 76.15,-352.03 83.15,-352.03\"/>\n",
              "</g>\n",
              "<!-- loss -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>loss</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"49.65\" cy=\"-251\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"49.65\" y=\"-247.3\" font-family=\"Times,serif\" font-size=\"14.00\">loss</text>\n",
              "</g>\n",
              "<!-- predict&#45;&gt;loss -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>predict&#45;&gt;loss</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M72.54,-306.17C68.99,-297.77 64.61,-287.42 60.64,-278.03\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"63.82,-276.55 56.71,-268.71 57.37,-279.28 63.82,-276.55\"/>\n",
              "</g>\n",
              "<!-- gradient -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>gradient</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"39.65\" cy=\"-164\" rx=\"39.79\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"39.65\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\">gradient</text>\n",
              "</g>\n",
              "<!-- loss&#45;&gt;gradient -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>loss&#45;&gt;gradient</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M47.62,-232.8C46.25,-221.16 44.42,-205.55 42.85,-192.24\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"46.31,-191.7 41.67,-182.18 39.36,-192.52 46.31,-191.7\"/>\n",
              "</g>\n",
              "<!-- adjust -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>adjust</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"73.65\" cy=\"-91\" rx=\"31.7\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"73.65\" y=\"-87.3\" font-family=\"Times,serif\" font-size=\"14.00\">adjust</text>\n",
              "</g>\n",
              "<!-- gradient&#45;&gt;adjust -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>gradient&#45;&gt;adjust</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M47.7,-146.17C51.77,-137.69 56.79,-127.21 61.32,-117.73\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"64.48,-119.24 65.65,-108.71 58.17,-116.21 64.48,-119.24\"/>\n",
              "</g>\n",
              "<!-- adjust&#45;&gt;predict -->\n",
              "<g id=\"edge6\" class=\"edge\">\n",
              "<title>adjust&#45;&gt;predict</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M79.57,-108.78C82.98,-119.31 86.91,-133.27 88.65,-146 95.84,-198.77 89.19,-261.1 84.13,-295.94\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"80.67,-295.41 82.63,-305.82 87.59,-296.46 80.67,-295.41\"/>\n",
              "<text text-anchor=\"middle\" x=\"109.65\" y=\"-203.8\" font-family=\"Times,serif\" font-size=\"14.00\">repeat</text>\n",
              "</g>\n",
              "<!-- stop -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>stop</title>\n",
              "<ellipse fill=\"none\" stroke=\"black\" cx=\"73.65\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
              "<text text-anchor=\"middle\" x=\"73.65\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">stop</text>\n",
              "</g>\n",
              "<!-- adjust&#45;&gt;stop -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>adjust&#45;&gt;stop</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M73.65,-72.81C73.65,-64.79 73.65,-55.05 73.65,-46.07\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"77.15,-46.03 73.65,-36.03 70.15,-46.03 77.15,-46.03\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x7b5e542d0410>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install graphviz\n",
        "from graphviz import Digraph\n",
        "\n",
        "dot = Digraph(comment='Gradient Descent Process')\n",
        "\n",
        "dot.edge('init', 'predict')\n",
        "dot.edge('predict', 'loss')\n",
        "dot.edge('loss', 'gradient')\n",
        "dot.edge('gradient', 'adjust')\n",
        "dot.edge('adjust', 'stop')\n",
        "dot.edge('adjust', 'predict', label='repeat')\n",
        "\n",
        "# Render in notebook\n",
        "dot.render('gradient_descent', format='png', view=True)  # saves and opens the file\n",
        "\n",
        "# To just display in Jupyter notebook:\n",
        "dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uTnK-QD7Ao4"
      },
      "source": [
        "#  From Theory to Practice: Creating a Learner from scratch on MNIST\n",
        "\n",
        "Using the [MNIST dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) which is a collection of handwritten digits, I'll apply SGD to train a neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrcDcHLe8DaR"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJvV4jX8DIZ",
        "outputId": "c7223b77-e775-4c66-8f70-625407cb2078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m792.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "matplotlib.rc('image', cmap='Greys')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbp8zx6U9HO4"
      },
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "\n",
        "In chapter <4>, only a sample of the mnist dataset was used, but in my case I need data for all digits.\n",
        "To do that, I went onto fastai[ documentation page](https://docs.fast.ai/data.external.html) to check available URLs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxmbS2dT-9J8",
        "outputId": "72a81d2e-dc12-410c-d770-f9041892eaab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function untar_data in module fastai.data.external:\n",
            "\n",
            "untar_data(url: 'str', archive: 'Path' = None, data: 'Path' = None, c_key: 'str' = 'data', force_download: 'bool' = False, base: 'str' = None) -> 'Path'\n",
            "    Download `url` using `FastDownload.get`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(untar_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "aAhZSkaU9G07",
        "outputId": "609b84c0-a952-42b3-c779-a017689f319d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.14% [3219456/3214948 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Path('/root/.fastai/data/mnist_sample/train'), Path('/root/.fastai/data/mnist_sample/labels.csv'), Path('/root/.fastai/data/mnist_sample/valid')]\n",
            "[Path('/root/.fastai/data/mnist_sample/train/3'), Path('/root/.fastai/data/mnist_sample/train/7')]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Path('/root/.fastai/data/mnist_png/testing'), Path('/root/.fastai/data/mnist_png/training')]\n",
            "[Path('/root/.fastai/data/mnist_png/training/0'), Path('/root/.fastai/data/mnist_png/training/1'), Path('/root/.fastai/data/mnist_png/training/2'), Path('/root/.fastai/data/mnist_png/training/3'), Path('/root/.fastai/data/mnist_png/training/4'), Path('/root/.fastai/data/mnist_png/training/5'), Path('/root/.fastai/data/mnist_png/training/6'), Path('/root/.fastai/data/mnist_png/training/7'), Path('/root/.fastai/data/mnist_png/training/8'), Path('/root/.fastai/data/mnist_png/training/9')]\n",
            "[Path('/root/.fastai/data/mnist_png/testing/0'), Path('/root/.fastai/data/mnist_png/testing/1'), Path('/root/.fastai/data/mnist_png/testing/2'), Path('/root/.fastai/data/mnist_png/testing/3'), Path('/root/.fastai/data/mnist_png/testing/4'), Path('/root/.fastai/data/mnist_png/testing/5'), Path('/root/.fastai/data/mnist_png/testing/6'), Path('/root/.fastai/data/mnist_png/testing/7'), Path('/root/.fastai/data/mnist_png/testing/8'), Path('/root/.fastai/data/mnist_png/testing/9')]\n"
          ]
        }
      ],
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "print(path.ls())\n",
        "print((path/'train').ls().sorted())\n",
        "path = untar_data(URLs.MNIST)\n",
        "print(path.ls())\n",
        "print((path/'training').ls().sorted())\n",
        "print((path/'testing').ls().sorted())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuDnOj9iEbhq",
        "outputId": "2927e180-563d-4207-d6e6-a05e1ad4072d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5923\n"
          ]
        }
      ],
      "source": [
        "train_0 = Path(os.path.join(path,'training','0')).ls().sorted()\n",
        "print(len(train_0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8JgRmi3B4qi"
      },
      "source": [
        "I checked with the `sorted` that I do, in fact, have all the digits needed.\n",
        "Now let's check the type and shape of images in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "WIkl9R0EB4c5",
        "outputId": "da1a7980-5564-48e2-8fd8-5182bd1a8890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28)\n"
          ]
        },
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+trwt4W1TxfrcOl6VDvlc5eRvuRL3Zj2A/wD1V0Xj74YXvgeKG5S+TU7NmMU00MRUW8oCnY/JAzu455x0FcHVnTrC51XUrbT7OMyXNzKsUaDuxOBXrmveMYfhfpk/gfwsG/tCJ1e/1TOC8pwWVR2GMLnIxg9+aboGsX/jvwD8SLrX7tpXjitrqPaAio6iTGAOMHYo98eteOV0ngC8t7D4gaDd3cyQ28V5G0kjnCqM9SfSvRvFXwjgttb1LxDr/i6xs9Hup3uY5QpeaYMxbaqjAJwe2fpXDeJ/Fdk+nHw34Whez8PKweTzADNeSA/6yRuuPReAPT046iiiiv/Z",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDklEQVR4AWNgGHhgPP/vfCMczjB49+fPn7fYJc0e//3z/uUfSzZMaS6bB3/+/jkV8udvFUSSCUnNzAMyQJ4Rz0EGXQxJY29GxkOljC/OT2JiRNICZoLcspnHu1KUgeHvZzQHqy39+/JCCETH3z9LUbSyb/rzwV0YZCcQ/P1zGMKAkpZ//tjDBdAlj/3dB5dj+P/3CJgD9YqPwf9NCMl//y8gOAwMoX+eScL47O1/d/HAOCA69M99GJe9+c9DdxgHTIf+mQjlGyz9sxZFioEh7O9DiEjRu7+L0OSAxv6cZCAbuunh3/vLLTAl//x5eh0Yl0ea0KUYGGSO/wHG1p+XMJtRVUg2ACV7VVEFB4IHAKxwbkRtVspVAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "im0_path = train_0[0]\n",
        "im0 = Image.open(im0_path)\n",
        "print(im0.shape)\n",
        "im0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28_HSKqUDY5Q"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "To prepare the training set, the following steps are necessary:\n",
        "\n",
        "1. Collect all training images.\n",
        "2. Normalize pixel values to the range [0, 1].\n",
        "3. Reshape the images into a stack of flattened vectors with shape (num_images, 28 * 28) in float32 format.\n",
        "4. Prepare the corresponding labels (y).\n",
        "\n",
        "### Multi-Class Classification\n",
        "\n",
        "Since there are multiple categories, this is no longer a binary classification problem. Two intuitive approaches arise:\n",
        "\n",
        "* Binary Classifiers per Label\n",
        "  * Train an independent binary classifier for each label.\n",
        "  * **Issue**: Fails to account for mutual exclusivity (an image could erroneously receive multiple labels).\n",
        "\n",
        "* One-Hot Encoding\n",
        "\n",
        "  * Represent labels as sparse vectors (e.g., [0, 1, 0, ..., 0] for label 1).\n",
        "  * **Drawback**: Memory-inefficient (stores n_classes values per sample) and less intuitive for direct indexing.\n",
        "\n",
        "* Integer Labels\n",
        "A simpler and more efficient approach is to use integer encoding (e.g., y = 2 for class 2). Advantages include:\n",
        "\n",
        "  * Memory efficiency: Stores a single integer per sample instead of a full vector.\n",
        "  * Debugging simplicity: Easier to interpret and index during model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rctsk_6mHEB2"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "def get_set(path, set_type=\"training\"):\n",
        "  \"\"\"Returns a set (x, y) of tensors.\n",
        "  Where x is the dependent variable and y the independant variable.\n",
        "  Args:\n",
        "    path (str): full path to the root folder containing the images.\n",
        "    set_type (str): Desired set. Values [training, test].\n",
        "  Returns:\n",
        "    x(n_images, 28 * 28), y(n_images).\n",
        "  \"\"\"\n",
        "  imgs = []\n",
        "  labels = []\n",
        "  for idx, digit_path in enumerate((path/set_type).ls().sorted()):\n",
        "      img_paths = digit_path.ls().sorted()\n",
        "      # Convert each image to a tensor\n",
        "      # And scale it accordingly into [0,1] range\n",
        "      imgs += [transforms.ToTensor()(Image.open(im_path)) for im_path in img_paths]\n",
        "      # Add one label per image\n",
        "      labels += [idx for _ in range(len(img_paths))]\n",
        "\n",
        "  # Stack into tensors\n",
        "  return torch.stack(imgs).float().view(-1, 28*28), torch.tensor(labels, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY9PGUHoIWd9"
      },
      "outputs": [],
      "source": [
        "train_x, train_y =  get_set(path, \"training\")\n",
        "test_x, test_y =  get_set(path, \"testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LQTRtNtRn6r",
        "outputId": "e94d69b5-c9e4-4e8c-f9c2-377c69832f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([60000, 784]), dtype: torch.float32\n",
            "Label shape: torch.Size([60000]), dtype: torch.int64\n",
            "Sample labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input shape: {train_x.shape}, dtype: {train_x.dtype}\")\n",
        "print(f\"Label shape: {train_y.shape}, dtype: {train_y.dtype}\")\n",
        "print(f\"Sample labels: {train_y[:10]}\")  # Should be integers like [0, 0, 0, 1, 1, 1, ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9YCiB_FUdI4",
        "outputId": "d45588ba-9833-4c8f-cfcc-25b686402c09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([784]), tensor(0))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dset = list(zip(train_x,train_y))\n",
        "test_dset= list(zip(test_x,test_y))\n",
        "x,y = train_dset[0]\n",
        "x.shape, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2O5Y0VbbCib"
      },
      "source": [
        "### Core Components\n",
        "Now that we have built both our training and test sets into tensors, it's time to create the necessary elements for learning:\n",
        "\n",
        "1. **Dataloader**\n",
        "\n",
        "Is class that shuffles the dataset and creates mini-batches from it.\n",
        "\n",
        "A mini-batch is a random selection of few data items from the dataset. Over which the loss function will be estimated.\n",
        "The point of using mini-batches instead of the whole dataset or a single data item is to find a compromise between calculation time and model performance.\n",
        "\n",
        "The DataLoader also creates an iterator over these mini-batches of collections.\n",
        "\n",
        "2. **Model**\n",
        "\n",
        "The neural network we will use for prediction.\n",
        "This neural network will consist of three linear layers with a non-linear activation in between.\n",
        "\n",
        "3. **Optimizer**\n",
        "\n",
        "Is a class that handles the stochastic gradient descent step. In essence, it computes the gradient for the set of parameters and then adjust these parameters with the help of the learning rate.\n",
        "\n",
        "4. **Loss function**\n",
        "\n",
        "It is important to choose a loss function that will reflect the impact of small changes in the weights.\n",
        "In this chapter the `mnist_loss` was used. It is a function that measures the distance between `predictions` and `targets` in the case of a binary classification.\n",
        "However, in my particular case, I am dealing with multi-class classification, and I need a meaningful function for learning.\n",
        "\n",
        "The default function for multi-class classification is the cross-enthropy.\n",
        "\n",
        "Cross-entropy measures the variation between the predicted and actual probability distributions for the set of labels in our problem.\n",
        "A a perfect cross-entropy value is 0.\n",
        "\n",
        "In multi-class classification, a `softmax` activation plus a cross-entropy loss is used. This outputs a vector of predicted probabilities over the input labels.\n",
        "\n",
        "5. **Metric**\n",
        "\n",
        "While the loss function is determined in a way that drives automated learning, the metric is determined to ease human understanding.\n",
        "\n",
        "An intuitive metric for model performance remains accuracy. In that we measure the number of correct predictions over the total number of predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMgwvBOPZ7cX"
      },
      "outputs": [],
      "source": [
        "# Set the seed so that the results are reproductible\n",
        "# 1. DataLoader\n",
        "\n",
        "train_dl = DataLoader(train_dset, batch_size= 16, shuffle = True)\n",
        "test_dl = DataLoader(test_dset, batch_size = len(test_dset))\n",
        "\n",
        "# 2. Model\n",
        "\n",
        "pred_model = nn.Sequential(\n",
        "    nn.Linear(28*28, 30), # The total mix of pixels can output 30 features\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,10) # Takes 30 features as input and outputs 10 predictions\n",
        ")\n",
        "\n",
        "# 3. Optimizer\n",
        "\n",
        "class Optimizer:\n",
        "  def __init__(self, params, lr):\n",
        "    self.params = list(params)\n",
        "    self.lr = lr\n",
        "  def step(self, *args, **kwargs):\n",
        "    for p in self.params: p.data -= p.grad.data * self.lr\n",
        "  def zero_grad(self, *args, **kwargs):\n",
        "    for p in self.params: p.grad.zero_()\n",
        "\n",
        "opt = Optimizer(pred_model.parameters(), lr = 0.01)\n",
        "\n",
        "# 4. Loss function\n",
        "# Provided by pytorch\n",
        "import torch.nn as nn\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# 5 . Metric -- Accuracy\n",
        "def batch_accuracy(y_pred, target):\n",
        "  probs = torch.softmax(y_pred, dim=1)\n",
        "  preds = probs.argmax(dim=1)\n",
        "  correct = (preds == target)\n",
        "  return correct.sum().float() / float( target.size(0) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elj-lAOKEZSC"
      },
      "source": [
        "Putting it all together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWH2rolsKqe8"
      },
      "outputs": [],
      "source": [
        "def calc_grads(x, y, model, loss_func):\n",
        "    preds = model(x)\n",
        "    loss = loss_func(preds, y)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "def train_epoch(model, dl, loss_func, lr):\n",
        "    opt = Optimizer(model.parameters(), lr=lr)\n",
        "    for x, y in dl:\n",
        "        loss_value = calc_grads(x, y, model, loss_func)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    return round(loss_value.item(), 4)\n",
        "\n",
        "def validate_epoch(model, dl):\n",
        "  with torch.no_grad():\n",
        "    accs = [batch_accuracy(model(xb), yb) for xb, yb in dl]\n",
        "  return round(torch.stack(accs).mean().item(), 4)\n",
        "\n",
        "def train_model(model, train_dl, test_dl, loss_func, lr = 0.0001, epochs = 4):\n",
        "    for i in range(epochs):\n",
        "        loss_value = train_epoch(model, train_dl, loss_func, lr)\n",
        "        accuracy = validate_epoch(model, test_dl)\n",
        "        print(f\"| epoch {i+1:<2} | error: {loss_value:<7.4f} | accuracy: {accuracy:<7.4f} |\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-_r_yfXLzei",
        "outputId": "008a98ce-9b94-444d-f111-1dd640e2381a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch 1  | error: 0.0836  | accuracy: 0.9203  |\n",
            "| epoch 2  | error: 0.2558  | accuracy: 0.9261  |\n",
            "| epoch 3  | error: 0.1788  | accuracy: 0.9328  |\n",
            "| epoch 4  | error: 0.0523  | accuracy: 0.9385  |\n",
            "| epoch 5  | error: 0.1467  | accuracy: 0.9402  |\n",
            "| epoch 6  | error: 0.6077  | accuracy: 0.9460  |\n",
            "| epoch 7  | error: 0.0939  | accuracy: 0.9504  |\n",
            "| epoch 8  | error: 0.0863  | accuracy: 0.9506  |\n",
            "| epoch 9  | error: 0.1196  | accuracy: 0.9521  |\n",
            "| epoch 10 | error: 0.2824  | accuracy: 0.9547  |\n",
            "| epoch 11 | error: 0.3837  | accuracy: 0.9562  |\n",
            "| epoch 12 | error: 0.3543  | accuracy: 0.9574  |\n",
            "| epoch 13 | error: 0.0555  | accuracy: 0.9579  |\n",
            "| epoch 14 | error: 0.2933  | accuracy: 0.9599  |\n",
            "| epoch 15 | error: 0.2442  | accuracy: 0.9607  |\n",
            "| epoch 16 | error: 0.1736  | accuracy: 0.9609  |\n",
            "| epoch 17 | error: 0.0730  | accuracy: 0.9624  |\n",
            "| epoch 18 | error: 0.0323  | accuracy: 0.9620  |\n",
            "| epoch 19 | error: 0.1359  | accuracy: 0.9625  |\n",
            "| epoch 20 | error: 0.2637  | accuracy: 0.9635  |\n"
          ]
        }
      ],
      "source": [
        "train_model(pred_model, train_dl, test_dl, loss_func, lr = 0.01, epochs = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sQFP04CVeDX"
      },
      "source": [
        "### Fastai Equivalent Implementation\n",
        "\n",
        "These steps can be replicated via the fastai modules as follow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "pzNhUFMdVjGT",
        "outputId": "4e91716a-a6b4-42c6-ff41-b15ad2819ded"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.333567</td>\n",
              "      <td>0.342215</td>\n",
              "      <td>0.897300</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.283738</td>\n",
              "      <td>0.268222</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.213385</td>\n",
              "      <td>0.225471</td>\n",
              "      <td>0.933200</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.184340</td>\n",
              "      <td>0.203401</td>\n",
              "      <td>0.937900</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.235486</td>\n",
              "      <td>0.183110</td>\n",
              "      <td>0.947000</td>\n",
              "      <td>00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.169792</td>\n",
              "      <td>0.171133</td>\n",
              "      <td>0.951400</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.153068</td>\n",
              "      <td>0.152203</td>\n",
              "      <td>0.955200</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.158674</td>\n",
              "      <td>0.143634</td>\n",
              "      <td>0.957900</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.139212</td>\n",
              "      <td>0.135299</td>\n",
              "      <td>0.959600</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.107892</td>\n",
              "      <td>0.128524</td>\n",
              "      <td>0.961600</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.101543</td>\n",
              "      <td>0.125986</td>\n",
              "      <td>0.961300</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.081692</td>\n",
              "      <td>0.129580</td>\n",
              "      <td>0.960900</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.134035</td>\n",
              "      <td>0.114556</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>00:11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.085697</td>\n",
              "      <td>0.108402</td>\n",
              "      <td>0.967500</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.087118</td>\n",
              "      <td>0.114101</td>\n",
              "      <td>0.964700</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dls = DataLoaders(train_dl, test_dl)\n",
        "pred_model = nn.Sequential(\n",
        "    nn.Linear(28*28, 30), # The total mix of pixels can output 30 features\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,10) # Takes 30 features as input and outputs 10 predictions\n",
        ")\n",
        "learn = Learner(dls, pred_model, opt_func = SGD, loss_func = F.cross_entropy, metrics=accuracy)\n",
        "learn.fit(15, 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bHW0nbx7lBn"
      },
      "source": [
        "# Recap\n",
        "\n",
        "* The universal approximation theorem states that, even a shallow neural network with a single non-linear activation can approximate any continuous function as closely as needed. However, in practice, deeper models are often chosen for better efficiency, generalization, and training performance, as shown in our final example.\n",
        "\n",
        "* In this exercise, we walked through the complete workflow of building a learner from scratch: preparing the dataset, batching data, defining the model, optimizing with stochastic gradient descent, and evaluating performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
