{
  "hash": "3824c4e90562f3ef2163c2fce021925b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Neural Networks Foundation — From Theory to Practice\nexecute:\n  freeze: true\nnumber-sections: true\n---\n\n# Introduction\n\nFor any machine learning or deep learning model to improve, it must learn from its own performance—specifically, by iteratively adjusting its parameters (weights) until predictions align with reality.\n\nStochastic Gradient Descent (SGD) is the cornerstone of this optimization process and remains the  widely used optimization algorithm in modern AI.\n\nIn this article, I'll:\n\n* Build an intuitive understanding of SGD.\n\n* Walk through a simple example of gradient descent.\n\n* Apply these concepts by creating a learner from scratch and training it on the MNIST dataset.\n\n# The Intuition Behind Gradient Descent\n\nConsider the case where we have a set of 2-D points $p(x, y)$ emulating a natural phenomenon, and we want to model their behavior using a quadratic equation:\n\n$y = a.x^2 + b.x + c$\n\nTo find the best values for $a$, $b$, and $c$, we usually would:\n\n* Choose initial (random) values for $a$, $b$, and $c$.\n\n* Make predictions $\\hat{y}$ for all $x$ using these weights.\n\n* Compare predictions to the true $y$ values and compute the error.\n\n* Figure out how to adjust $a$, $b$, and $c$ to reduce the error (increase or decrease).\n\n* Repeat this process until the error is as small as possible.\n\nHowever, how would we instill this intuition on how to correctly adjust the weights to our model?\n\nThe answer lies in gradient descent.\n\nThe idea behind gradient descent is to compute the derivative of a function ( in our case, the error function) at some point (the point being the weights chosen). This will tell us how steeply the error changes with respect to each parameter.\n\nAnd since we are trying to minimize this error, take iterative steps in the opposite direction of the gradient because that's where the steepest descent is.\n\n$w=w - \\eta⋅\\nabla{L}$\n\nWhere:\n\n  $\\eta$ is the learning rate\n\n  $\\nabla{L}$ is the gradient of the loss function\n\n## Example\n\nLet's say our loss function is as follow:\n\n $f(w) = (w -5)^2$\n\nAt first glance, it is obvious that the value of $w$ that would minimize $f(w)$ is 5.\n\nBut let's do that with SGD.\n\n* Start with $w_0 = 0$, and a learning rate $\\eta = 0.1$.\n\n* Compute gradient $\\nabla{f(w)} = 2 * (w -5)$\n  \n* Iteration 1:\n  \n    $w_1 = w_0 - \\eta⋅\\nabla{f(w_0)} = 0 - 0.1 * 2(0 - 5) = 1$\n\n* Iteration 2:\n  \n    $w_2 = w_1 - \\eta⋅\\nabla{f(w_1)} = 1 - 0.1 * 2(1 - 5) = 1.4$\n\nAs we can see each step is moving us closer to the solution $w = 5$.\n\n## Why \"Stochastic\"?\n\nIn Stochastic Gradient Descent (SGD), instead of computing the gradient using the entire dataset at once—which would be computationally heavy, we use just one data point or a small random batch.\nThis makes updates faster and helps the model escape local minima, as it adds a bit of randomness.\n\n\n\n```python\n!pip install graphviz\nfrom graphviz import Digraph\n\ndot = Digraph(comment='Gradient Descent Process')\n\ndot.edge('init', 'predict')\ndot.edge('predict', 'loss')\ndot.edge('loss', 'gradient')\ndot.edge('gradient', 'adjust')\ndot.edge('adjust', 'stop')\ndot.edge('adjust', 'predict', label='repeat')\n\n# Render in notebook\ndot.render('gradient_descent', format='png', view=True)  # saves and opens the file\n\n# To just display in Jupyter notebook:\ndot\n```\n\n    Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n    \n\n\n\n\n    \n![svg](03-neural_net_foundation.qmd_files/03-neural_net_foundation.qmd_1_1.svg)\n    \n\n\n\n#  From Theory to Practice: Creating a Learner from scratch on MNIST\n\nUsing the [MNIST dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) which is a collection of handwritten digits, I'll apply SGD to train a neural network.\n\n## Setup\n\n\n```python\n#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n! [ -e /content ] && pip install -Uqq fastbook\nfrom fastai.vision.all import *\nfrom fastbook import *\nmatplotlib.rc('image', cmap='Greys')\n```\n\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m792.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n    \u001b[?25hMounted at /content/gdrive\n    \n\n## Dataset Preparation\n\n\nIn chapter <4>, only a sample of the mnist dataset was used, but in my case I need data for all digits.\nTo do that, I went onto fastai [documentation page](https://docs.fast.ai/data.external.html) to check available URLs.\n\n\n```python\nhelp(untar_data)\n```\n\n    Help on function untar_data in module fastai.data.external:\n    \n    untar_data(url: 'str', archive: 'Path' = None, data: 'Path' = None, c_key: 'str' = 'data', force_download: 'bool' = False, base: 'str' = None) -> 'Path'\n        Download `url` using `FastDownload.get`\n    \n    \n\n\n```python\npath = untar_data(URLs.MNIST_SAMPLE)\nprint(path.ls())\nprint((path/'train').ls().sorted())\npath = untar_data(URLs.MNIST)\nprint(path.ls())\nprint((path/'training').ls().sorted())\nprint((path/'testing').ls().sorted())\n```\n\n\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n\n\n\n\n\n<div>\n  <progress value='3219456' class='' max='3214948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n  100.14% [3219456/3214948 00:00&lt;00:00]\n</div>\n\n\n\n    [Path('/root/.fastai/data/mnist_sample/train'), Path('/root/.fastai/data/mnist_sample/labels.csv'), Path('/root/.fastai/data/mnist_sample/valid')]\n    [Path('/root/.fastai/data/mnist_sample/train/3'), Path('/root/.fastai/data/mnist_sample/train/7')]\n    \n\n\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n\n\n\n\n\n<div>\n  <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n  100.03% [15687680/15683414 00:00&lt;00:00]\n</div>\n\n\n\n    [Path('/root/.fastai/data/mnist_png/testing'), Path('/root/.fastai/data/mnist_png/training')]\n    [Path('/root/.fastai/data/mnist_png/training/0'), Path('/root/.fastai/data/mnist_png/training/1'), Path('/root/.fastai/data/mnist_png/training/2'), Path('/root/.fastai/data/mnist_png/training/3'), Path('/root/.fastai/data/mnist_png/training/4'), Path('/root/.fastai/data/mnist_png/training/5'), Path('/root/.fastai/data/mnist_png/training/6'), Path('/root/.fastai/data/mnist_png/training/7'), Path('/root/.fastai/data/mnist_png/training/8'), Path('/root/.fastai/data/mnist_png/training/9')]\n    [Path('/root/.fastai/data/mnist_png/testing/0'), Path('/root/.fastai/data/mnist_png/testing/1'), Path('/root/.fastai/data/mnist_png/testing/2'), Path('/root/.fastai/data/mnist_png/testing/3'), Path('/root/.fastai/data/mnist_png/testing/4'), Path('/root/.fastai/data/mnist_png/testing/5'), Path('/root/.fastai/data/mnist_png/testing/6'), Path('/root/.fastai/data/mnist_png/testing/7'), Path('/root/.fastai/data/mnist_png/testing/8'), Path('/root/.fastai/data/mnist_png/testing/9')]\n    \n\n\n```python\ntrain_0 = Path(os.path.join(path,'training','0')).ls().sorted()\nprint(len(train_0))\n```\n\n    5923\n    \n\nI checked with the `sorted` that I do, in fact, have all the digits needed.\nNow let's check the type and shape of images in the dataset.\n\n\n```python\nim0_path = train_0[0]\nim0 = Image.open(im0_path)\nprint(im0.shape)\nim0\n```\n\n    (28, 28)\n    \n\n\n\n\n    \n![png](03-neural_net_foundation.qmd_files/03-neural_net_foundation.qmd_10_1.png)\n    \n\n\n\n### Preprocessing\n\nTo prepare the training set, the following steps are necessary:\n\n1. Collect all training images.\n2. Normalize pixel values to the range [0, 1].\n3. Reshape the images into a stack of flattened vectors with shape (num_images, 28 * 28) in float32 format.\n4. Prepare the corresponding labels (y).\n\n### Multi-Class Classification\n\nSince there are multiple categories, this is no longer a binary classification problem. Two intuitive approaches arise:\n\n* Binary Classifiers per Label\n  * Train an independent binary classifier for each label.\n  * **Issue**: Fails to account for mutual exclusivity (an image could erroneously receive multiple labels).\n\n* One-Hot Encoding\n\n  * Represent labels as sparse vectors (e.g., [0, 1, 0, ..., 0] for label 1).\n  * **Drawback**: Memory-inefficient (stores n_classes values per sample) and less intuitive for direct indexing.\n\n* Integer Labels\n\nA simpler and more efficient approach is to use integer encoding (e.g., y = 2 for class 2). Advantages include:\n\n  * Memory efficiency: Stores a single integer per sample instead of a full vector.\n  * Debugging simplicity: Easier to interpret and index during model evaluation.\n\n\n```python\nfrom PIL import Image\nimport torch\nfrom torchvision import transforms\n\ndef get_set(path, set_type=\"training\"):\n  \"\"\"Returns a set (x, y) of tensors.\n  Where x is the dependent variable and y the independant variable.\n  Args:\n    path (str): full path to the root folder containing the images.\n    set_type (str): Desired set. Values [training, test].\n  Returns:\n    x(n_images, 28 * 28), y(n_images).\n  \"\"\"\n  imgs = []\n  labels = []\n  for idx, digit_path in enumerate((path/set_type).ls().sorted()):\n      img_paths = digit_path.ls().sorted()\n      # Convert each image to a tensor\n      # And scale it accordingly into [0,1] range\n      imgs += [transforms.ToTensor()(Image.open(im_path)) for im_path in img_paths]\n      # Add one label per image\n      labels += [idx for _ in range(len(img_paths))]\n\n  # Stack into tensors\n  return torch.stack(imgs).float().view(-1, 28*28), torch.tensor(labels, dtype=torch.long)\n```\n\n\n```python\ntrain_x, train_y =  get_set(path, \"training\")\ntest_x, test_y =  get_set(path, \"testing\")\n```\n\n\n```python\nprint(f\"Input shape: {train_x.shape}, dtype: {train_x.dtype}\")\nprint(f\"Label shape: {train_y.shape}, dtype: {train_y.dtype}\")\nprint(f\"Sample labels: {train_y[:10]}\")  # Should be integers like [0, 0, 0, 1, 1, 1, ...]\n```\n\n    Input shape: torch.Size([60000, 784]), dtype: torch.float32\n    Label shape: torch.Size([60000]), dtype: torch.int64\n    Sample labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    \n\n\n```python\ntrain_dset = list(zip(train_x,train_y))\ntest_dset= list(zip(test_x,test_y))\nx,y = train_dset[0]\nx.shape, y\n```\n\n\n\n\n    (torch.Size([784]), tensor(0))\n\n\n\n### Core Components\nNow that we have built both our training and test sets into tensors, it's time to create the necessary elements for learning:\n\n1. **Dataloader**\n\nIs class that shuffles the dataset and creates mini-batches from it.\n\nA mini-batch is a random selection of few data items from the dataset. Over which the loss function will be estimated.\nThe point of using mini-batches instead of the whole dataset or a single data item is to find a compromise between calculation time and model performance.\n\nThe DataLoader also creates an iterator over these mini-batches of collections.\n\n2. **Model**\n\nThe neural network we will use for prediction.\nThis neural network will consist of three linear layers with a non-linear activation in between.\n\n3. **Optimizer**\n\nIs a class that handles the stochastic gradient descent step. In essence, it computes the gradient for the set of parameters and then adjust these parameters with the help of the learning rate.\n\n4. **Loss function**\n\nIt is important to choose a loss function that will reflect the impact of small changes in the weights.\nIn this chapter the `mnist_loss` was used. It is a function that measures the distance between `predictions` and `targets` in the case of a binary classification.\nHowever, in my particular case, I am dealing with multi-class classification, and I need a meaningful function for learning.\n\nThe default function for multi-class classification is the cross-enthropy.\n\nCross-entropy measures the variation between the predicted and actual probability distributions for the set of labels in our problem.\nA a perfect cross-entropy value is 0.\n\nIn multi-class classification, a `softmax` activation plus a cross-entropy loss is used. This outputs a vector of predicted probabilities over the input labels.\n\n5. **Metric**\n\nWhile the loss function is determined in a way that drives automated learning, the metric is determined to ease human understanding.\n\nAn intuitive metric for model performance remains accuracy. In that we measure the number of correct predictions over the total number of predictions.\n\n\n\n```python\n# Set the seed so that the results are reproductible\n# 1. DataLoader\n\ntrain_dl = DataLoader(train_dset, batch_size= 16, shuffle = True)\ntest_dl = DataLoader(test_dset, batch_size = len(test_dset))\n\n# 2. Model\n\npred_model = nn.Sequential(\n    nn.Linear(28*28, 30), # The total mix of pixels can output 30 features\n    nn.ReLU(),\n    nn.Linear(30,10) # Takes 30 features as input and outputs 10 predictions\n)\n\n# 3. Optimizer\n\nclass Optimizer:\n  def __init__(self, params, lr):\n    self.params = list(params)\n    self.lr = lr\n  def step(self, *args, **kwargs):\n    for p in self.params: p.data -= p.grad.data * self.lr\n  def zero_grad(self, *args, **kwargs):\n    for p in self.params: p.grad.zero_()\n\nopt = Optimizer(pred_model.parameters(), lr = 0.01)\n\n# 4. Loss function\n# Provided by pytorch\nimport torch.nn as nn\nloss_func = nn.CrossEntropyLoss()\n\n# 5 . Metric -- Accuracy\ndef batch_accuracy(y_pred, target):\n  probs = torch.softmax(y_pred, dim=1)\n  preds = probs.argmax(dim=1)\n  correct = (preds == target)\n  return correct.sum().float() / float( target.size(0) )\n```\n\nPutting it all together:\n\n\n```python\ndef calc_grads(x, y, model, loss_func):\n    preds = model(x)\n    loss = loss_func(preds, y)\n    loss.backward()\n    return loss\n\ndef train_epoch(model, dl, loss_func, lr):\n    opt = Optimizer(model.parameters(), lr=lr)\n    for x, y in dl:\n        loss_value = calc_grads(x, y, model, loss_func)\n        opt.step()\n        opt.zero_grad()\n    return round(loss_value.item(), 4)\n\ndef validate_epoch(model, dl):\n  with torch.no_grad():\n    accs = [batch_accuracy(model(xb), yb) for xb, yb in dl]\n  return round(torch.stack(accs).mean().item(), 4)\n\ndef train_model(model, train_dl, test_dl, loss_func, lr = 0.0001, epochs = 4):\n    for i in range(epochs):\n        loss_value = train_epoch(model, train_dl, loss_func, lr)\n        accuracy = validate_epoch(model, test_dl)\n        print(f\"| epoch {i+1:<2} | error: {loss_value:<7.4f} | accuracy: {accuracy:<7.4f} |\" )\n```\n\n\n```python\ntrain_model(pred_model, train_dl, test_dl, loss_func, lr = 0.01, epochs = 20)\n```\n\n    | epoch 1  | error: 0.0836  | accuracy: 0.9203  |\n    | epoch 2  | error: 0.2558  | accuracy: 0.9261  |\n    | epoch 3  | error: 0.1788  | accuracy: 0.9328  |\n    | epoch 4  | error: 0.0523  | accuracy: 0.9385  |\n    | epoch 5  | error: 0.1467  | accuracy: 0.9402  |\n    | epoch 6  | error: 0.6077  | accuracy: 0.9460  |\n    | epoch 7  | error: 0.0939  | accuracy: 0.9504  |\n    | epoch 8  | error: 0.0863  | accuracy: 0.9506  |\n    | epoch 9  | error: 0.1196  | accuracy: 0.9521  |\n    | epoch 10 | error: 0.2824  | accuracy: 0.9547  |\n    | epoch 11 | error: 0.3837  | accuracy: 0.9562  |\n    | epoch 12 | error: 0.3543  | accuracy: 0.9574  |\n    | epoch 13 | error: 0.0555  | accuracy: 0.9579  |\n    | epoch 14 | error: 0.2933  | accuracy: 0.9599  |\n    | epoch 15 | error: 0.2442  | accuracy: 0.9607  |\n    | epoch 16 | error: 0.1736  | accuracy: 0.9609  |\n    | epoch 17 | error: 0.0730  | accuracy: 0.9624  |\n    | epoch 18 | error: 0.0323  | accuracy: 0.9620  |\n    | epoch 19 | error: 0.1359  | accuracy: 0.9625  |\n    | epoch 20 | error: 0.2637  | accuracy: 0.9635  |\n    \n\n### Fastai Equivalent Implementation\n\nThese steps can be replicated via the fastai modules as follow:\n\n\n```python\ndls = DataLoaders(train_dl, test_dl)\npred_model = nn.Sequential(\n    nn.Linear(28*28, 30), # The total mix of pixels can output 30 features\n    nn.ReLU(),\n    nn.Linear(30,30),\n    nn.ReLU(),\n    nn.Linear(30,10) # Takes 30 features as input and outputs 10 predictions\n)\nlearn = Learner(dls, pred_model, opt_func = SGD, loss_func = F.cross_entropy, metrics=accuracy)\nlearn.fit(15, 0.01)\n```\n\n\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n\n\n\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>accuracy</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.333567</td>\n      <td>0.342215</td>\n      <td>0.897300</td>\n      <td>00:11</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.283738</td>\n      <td>0.268222</td>\n      <td>0.922000</td>\n      <td>00:12</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.213385</td>\n      <td>0.225471</td>\n      <td>0.933200</td>\n      <td>00:17</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.184340</td>\n      <td>0.203401</td>\n      <td>0.937900</td>\n      <td>00:12</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.235486</td>\n      <td>0.183110</td>\n      <td>0.947000</td>\n      <td>00:12</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.169792</td>\n      <td>0.171133</td>\n      <td>0.951400</td>\n      <td>00:10</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.153068</td>\n      <td>0.152203</td>\n      <td>0.955200</td>\n      <td>00:09</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.158674</td>\n      <td>0.143634</td>\n      <td>0.957900</td>\n      <td>00:10</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.139212</td>\n      <td>0.135299</td>\n      <td>0.959600</td>\n      <td>00:10</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.107892</td>\n      <td>0.128524</td>\n      <td>0.961600</td>\n      <td>00:10</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.101543</td>\n      <td>0.125986</td>\n      <td>0.961300</td>\n      <td>00:09</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.081692</td>\n      <td>0.129580</td>\n      <td>0.960900</td>\n      <td>00:11</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.134035</td>\n      <td>0.114556</td>\n      <td>0.965000</td>\n      <td>00:11</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.085697</td>\n      <td>0.108402</td>\n      <td>0.967500</td>\n      <td>00:10</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.087118</td>\n      <td>0.114101</td>\n      <td>0.964700</td>\n      <td>00:10</td>\n    </tr>\n  </tbody>\n</table>\n\n\n# Recap\n\n* The universal approximation theorem states that, even a shallow neural network with a single non-linear activation can approximate any continuous function as closely as needed. However, in practice, deeper models are often chosen for better efficiency, generalization, and training performance, as shown in our final example.\n\n* In this exercise, we walked through the complete workflow of building a learner from scratch: preparing the dataset, batching data, defining the model, optimizing with stochastic gradient descent, and evaluating performance.\n\n",
    "supporting": [
      "03-neural_net_foundation_files"
    ],
    "filters": [],
    "includes": {}
  }
}